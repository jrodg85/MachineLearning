{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a801a4",
   "metadata": {},
   "source": [
    "# Generativa Adversarial Networks\n",
    "\n",
    "Las Generative Adversarial Networks (GANs) son un tipo de modelo de aprendizaje profundo generativo que consisten en dos redes neurales: una generadora y una discriminadora. La red generadora se encarga de crear nuevos datos (por ejemplo, imágenes), mientras que la red discriminadora se encarga de determinar si los datos creados por la red generadora son reales o falsos.\n",
    "\n",
    "El entrenamiento de una GAN consiste en una competencia entre la red generadora y la red discriminadora: la red generadora intenta crear datos cada vez más convincentes, mientras que la red discriminadora intenta hacer una clasificación cada vez más precisa. A medida que se entrena la GAN, la red generadora se vuelve cada vez más hábil en crear datos realistas, y la red discriminadora se vuelve cada vez más hábil en detectar datos falsos.\n",
    "\n",
    "En términos matemáticos, el problema se puede plantear como un juego entre dos jugadores: el generador y el discriminador. El generador trata de maximizar su función de pérdida, mientras que el discriminador trata de minimizarla. La función de pérdida es una medida de la capacidad del discriminador para diferenciar entre los datos reales y los falsos.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:828/format:webp/1*t78gwhhw-hn1CgXc1K89wA.png)\n",
    "\n",
    "En términos de implementación, esto se logra usando un optimizador para actualizar los pesos de las redes en cada iteración, basándose en la gradiente de la función de pérdida con respecto a los pesos. Al final del entrenamiento, el generador ha aprendido a producir datos que se parecen a los datos reales, mientras que el discriminador ha aprendido a ser un buen detector de datos falsos. Para conseguirlo se usa la diferencia entre las distribuciones estadísticas de **Kullback-Lieber**.\n",
    "\n",
    "A continuación veamos un ejemplos de código que implemeta una GAN en forma de una clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero cargamos las librerías que nos harán falta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Input, Dense, Reshape, Flatten, Dropout,\n",
    "                                     BatchNormalization, Activation, ZeroPadding2D, LeakyReLU,\n",
    "                                     UpSampling2D, Conv2D)\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self, image_shape, latent_dimension):\n",
    "        self.image_shape = image_shape\n",
    "        self.latent_dimension = latent_dimension\n",
    "        \n",
    "        # Definir el clasificador\n",
    "        self.discriminator = self.build_discriminator()\n",
    "  \n",
    "        # Definir el generador\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        input_generator= Input(shape=(self.latent_dimension,)) # También se llama Z o simplemente ruido\n",
    "        generated_image = self.generator(input_generator)\n",
    "        #Checking the validity of the generated image\n",
    "        output_discriminator = self.discriminator(generated_image)\n",
    "  \n",
    "        #Defining the combined model of the Generator and the Discriminator\n",
    "        self.gan = Model(input_generator, output_discriminator)\n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002,0.5))\n",
    "        \n",
    "    def build_generator(self):\n",
    "  \n",
    "        model = Sequential()\n",
    "  \n",
    "        #Building the input layer\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\",\n",
    "                        input_dim=latent_dimensions))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "          \n",
    "        model.add(UpSampling2D())\n",
    "          \n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.78))\n",
    "        model.add(Activation(\"relu\"))\n",
    "          \n",
    "        model.add(UpSampling2D())\n",
    "          \n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.78))\n",
    "        model.add(Activation(\"relu\"))\n",
    "          \n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "  \n",
    "  \n",
    "        #Generating the output image\n",
    "        noise = Input(shape=(latent_dimensions,))\n",
    "        image = model(noise)\n",
    "        \n",
    "        generator = Model(noise, image)\n",
    "        return generator\n",
    "\n",
    "    def build_discriminator(self):\n",
    "  \n",
    "        #Building the convolutional layers\n",
    "        #to classify whether an image is real or fake\n",
    "        model = Sequential()\n",
    "  \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2,\n",
    "                         input_shape=image_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "          \n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.82))\n",
    "        model.add(LeakyReLU(alpha=0.25))\n",
    "        model.add(Dropout(0.25))\n",
    "          \n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.82))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "          \n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.25))\n",
    "        model.add(Dropout(0.25))\n",
    "          \n",
    "        #La capa de salida\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "        image = Input(shape=self.image_shape)\n",
    "        validity = model(image)\n",
    "        \n",
    "        discriminator = Model(image, validity)\n",
    "        discriminator.compile(loss='binary_crossentropy',\n",
    "                              optimizer=Adam(0.0002,0.5),\n",
    "                              metrics=['accuracy'])\n",
    "        #Hacer al discriminador no entrenable para permitir al generador aprender del gradiente\n",
    "        discriminator.trainable = False\n",
    "        return discriminator\n",
    "\n",
    "    \n",
    "    def train(self,X, num_epochs=1500, batch_size=32, display_interval=150):\n",
    "        losses=[]\n",
    "        #Normalizing the input\n",
    "        X = (X / 127.5) - 1.\n",
    "          \n",
    "  \n",
    "        #Defining the Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "  \n",
    "        #Adding some noise \n",
    "        valid += 0.05 * np.random.random(valid.shape)\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        fake += 0.05 * np.random.random(fake.shape)\n",
    "  \n",
    "        for epoch in range(num_epochs):\n",
    "              \n",
    "            #Training the Discriminator\n",
    "              \n",
    "            #Sampling a random half of images\n",
    "            index = np.random.randint(0, X.shape[0], batch_size)\n",
    "            images = X[index]\n",
    "  \n",
    "            #Sampling noise and generating a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dimensions))\n",
    "            generated_images = self.generator.predict(noise)\n",
    "              \n",
    "  \n",
    "            #Training the discriminator to detect more accurately\n",
    "            #whether a generated image is real or fake\n",
    "            discm_loss_real = self.discriminator.train_on_batch(images, valid)\n",
    "            discm_loss_fake = self.discriminator.train_on_batch(generated_images, fake)\n",
    "            discm_loss = 0.5 * np.add(discm_loss_real, discm_loss_fake)\n",
    "              \n",
    "            #Training the Generator\n",
    "  \n",
    "            #Training the generator to generate images\n",
    "            #which pass the authenticity test\n",
    "            genr_loss = self.gan.train_on_batch(noise, valid)\n",
    "              \n",
    "            #Tracking the progress                \n",
    "            if epoch % display_interval == 0:\n",
    "                 self.display_images()\n",
    "                    \n",
    "    def display_images(self):\n",
    "        r, c = 4,4\n",
    "        noise = np.random.normal(0, 1, (r * c,self.latent_dimension))\n",
    "        generated_images = self.generator.predict(noise)\n",
    "  \n",
    "        #Scaling the generated images\n",
    "        generated_images = 0.5 * generated_images + 0.5\n",
    "  \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(generated_images[count, :,:,])\n",
    "                axs[i,j].axis('off')\n",
    "                count += 1\n",
    "        plt.show()               \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c531d9",
   "metadata": {},
   "source": [
    "Importante, fíjese que el discriminador se pone en `trainable = False` porque se está entrenando el modelo combinado, no el discriminador individual. El modelo combinado consiste en el generador y el discriminador combinados, donde el generador está tratando de engañar al discriminador para que prediga que las imágenes generadas son reales.\n",
    "\n",
    "El objetivo es mejorar el generador para que genere imágenes más realistas, por lo que solo se entrena el generador en este momento. Sin embargo, el discriminador todavía es necesario para calcular la validación de las imágenes generadas y para proporcionar retroalimentación al generador. Por eso, se congela la capacidad de entrenamiento del discriminador y solo se entrena el generador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df592733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar los datos en está ocasión CIFAR10\n",
    "# 10 posible clases de objetos\n",
    "(X, y), (_, _) = keras.datasets.cifar10.load_data()\n",
    "  \n",
    "#Escoger una de las clases\n",
    "X = X[y.flatten() == 8]\n",
    "\n",
    "#Defining the Input shape\n",
    "image_shape = (32, 32, 3)\n",
    "          \n",
    "latent_dimensions = 100\n",
    "\n",
    "gan = GAN(image_shape, latent_dimensions)\n",
    "\n",
    "gan.train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting some of the original images \n",
    "s=X[:40]\n",
    "s = 0.5 * s + 0.5\n",
    "f, ax = plt.subplots(5,8, figsize=(16,10))\n",
    "for i, image in enumerate(s):\n",
    "    ax[i//8, i%8].imshow(image)\n",
    "    ax[i//8, i%8].axis('off')\n",
    "          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting some of the last batch of generated images\n",
    "noise = np.random.normal(size=(40, latent_dimensions))\n",
    "generated_images = gan.generator.predict(noise)\n",
    "generated_images = 0.5 * generated_images + 0.5\n",
    "f, ax = plt.subplots(5,8, figsize=(16,10))\n",
    "for i, image in enumerate(generated_images):\n",
    "    ax[i//8, i%8].imshow(image)\n",
    "    ax[i//8, i%8].axis('off')\n",
    "          \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e25a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
