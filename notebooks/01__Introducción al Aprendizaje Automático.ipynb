{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d353f935",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "El aprendizaje automático o *machine learning* es una subárea dentro de la Inteligencia Artificial que aspira a encontrar patrones. El objetivo de encontrar esos patrones es poder diferntes tipos de problemas en base a la extracción de una serie de funciones, las cuales se basan en un conjunto de técnicas matemáticas. Estas técnicas permiten el aproximar una distribución de los datos en lo que se conoce como el **espacio de búsqueda**.\n",
    "\n",
    "El espacio de búsqueda se compone de todas las posibles soluciones al problema en cuestión que tratamos de solucionar. Entiéndase por solución la posible combinación de valores en cada una de las variables que componen un problema. Por ejemplo, en la imagen siguiente se puede ver un espacio de búsqueda compuesto por dos variables, $X_1$ y $X_2$. Cada uno de los puntos que sería una posible solución al problema.\n",
    "\n",
    "![Espacio de Busqueda](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg/640px-Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg.png)\n",
    "\n",
    "Aquellos puntos que conocemos dentro del espacio de búsqueda recibien por su parte el nombre de **patrones** y en la imagen anterior, se correcponderían con las x que están dentro del espacio de búsqueda y que nos darán la información para solucionar el problema que estemos enfocando y que representa ese espacio de búsqueda.\n",
    "\n",
    "Así pues, las técnicas de *machine learning* tratarán de acometer la resolución de un problema en base a los patrones y lo que se quiera hacer con ellas. De esa manera tendremos cada uno de los distintos tipos de problemas que se pueden acometer con este tipo de técnicas con la combinación tipo de información y tarea a realizar. Estos podrían identificarse en las siguientes categorías:\n",
    "\n",
    "\n",
    "* Problemas de clasificación.\n",
    "\n",
    " Este tipo de problemas son aquellos que tiene por objeto asignarle una clase o tipo a un ejemplo. Como particularidad son problemas conocidos como supervisados, es decir, necesitamos conocer la salida deseada a fin de ajustar el modelo. A su vez, estos se pueden dividir en dos subclases a razon de:\n",
    " \n",
    " * Clasificación binaria. En este caso solo existen dos posibles clases a las que asignarle a un patrón o solución. Un ejemplo de esto sería por ejemplo, el función de una señal de un sonar categorizar un objeto como una mina o una roca submarina. Otro ejemplo sería el decir si un paciente está sano o enfermo, etc.\n",
    " \n",
    " <img src=\"https://miro.medium.com/max/828/1*nB6MM2qFvnsCDhSuhNPcLA.webp\" alt=\"Clasificación\" width=\"450\"/>\n",
    " \n",
    " * Clasificición multiclase. En este caso en lugar de dos categorías tenemos más y cambia ligeramente el planteamiento ya que un patrón puede estar en una clase, en otra o en ninguna. En el caso de que se contemple este último hecho, implica, como veremos, meter una salida adicional para este último caso, pero ya se llegará a ese punto. Ejemplos de este tipo hay muchos, por ejemplo el reconocimiento de cual de los 10 dígitos se ha escrito a mano o la identidicación de que objeto se ve en una imagen serían solo algunos ejemplos clásicos.\n",
    " \n",
    " \n",
    "* Problemas de agrupamiento o custerización.\n",
    "Este tipo de problema al contrario que en el caso anterior, no tenemos la salida deseada si no que en lo que se basa es en agrupar los patrones por similitud o proximidad dentro del espacio de búsqueda.Este tipo de problemas serían aquellos más ligados al concepto conocido como **mineria de datos** puesto que eso es precisamente lo que tratamos de hacer encontrar relaciones entre los objetos sin saber a que categoría real pertenecen. Esto cae dentro de lo que se conoce como aprendizaje no supervisado. Ejemplos serían identificar trafico de red como maligno o benigno o mensajes de correo como spam o no.\n",
    "\n",
    "![Clustering](https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/EM_Clustering_of_Old_Faithful_data.gif/640px-EM_Clustering_of_Old_Faithful_data.gif)\n",
    " \n",
    "* Problemas de regresión.\n",
    "El último tipo de problemas a concretar es el que se conoce como regresión. Este tipo de problemas tiene como particularidad que no se pretende asignar una categoría o clasificar como en los casos anteriores si no extraer de los patrones una función que permita obtener un valor exacto dentro de un espacio continuo. Es posiblemente el tipo de problemas más frecuentes pero también, muchas veces, los más complicados de acometer. Ejemplos de este tipo de problemas podría ser, por ejemplo, el obtener el parámetro de pontencia a pasarle a una bombilla en función de la hora y los datos de iluminación ambiente, predicción de toxicidad en un agua por marea roja, etc.\n",
    "\n",
    "![Regresion](https://upload.wikimedia.org/wikipedia/commons/d/da/Gaussianprocess.gif)\n",
    " \n",
    " \n",
    "Para acometer cualquiera de estos problemas, utilizaremos un conjunto de técnicas cuya implementación queda bastante fuera del temario de este curso. Es por ello que para poder hacer uso de ellas vamos a utilizar el lenguaje Python junto con una serie de librería que nos facilitaran el uso de las técnicas para solucionar cada uno de los problemas que tenemos. En concreto, la primera de todas y posiblemente la más importante desde un punto de vista inicial sea la que se presenta a continuación `scikit-learn`.\n",
    "\n",
    "\n",
    " ## Scikit-learn, toma de contacto y un vistazo al pipeline de procesado\n",
    " \n",
    " `scikit-learn`es una librería de **Python** que aglutina y simplifica gran parte del flujo de trabajo en *machine learning*. En concreto cuenta con muchas implementaciones de las técnicas más habituales y varias de sus variantes así como clases para el preprocesado o preparación de los datos y otras para la selección de parámetros o modelos como pueden ser las medidas de rendimiento que veremos en una unidad posterior.\n",
    "\n",
    "Es un API muy bien diseñada y simple. Está orientado a objetos y todos comparten un interfaz consistente y simple. En ella destacan los siguientes elementos:\n",
    "\n",
    "* Estimators: cualquier objeto que pueda estimar algún parámetro basado en un dataset. La estimación se hace mediante el método fit y sólo necesita un dataset como entrada (en caso de entrenamiento supervisado el estimador necesitaría dos, los datos y las salidas). Cualquier otro parámetro necesario para guiar la estimación, es considerado un hiperparámetro.\n",
    "* Transformers: algunos estimators pueden transformar un dataset. El API de nuevo es simple, tiene un método transform() y el método acepta como parámetro el dataset. Devuelve el dataset transformado. Todos tienen un fit_transform que realiza las dos operaciones pero de forma optimizada.\n",
    "* Predictors: algunos estimators pueden hacer predicciones también si se aplican sobre un dataset. Tiene un método predict() que recibe un dataset y devuelve las predicciones en el mismo formato. Tiene también un método score() que devuelve un valor que indica lo bien que se ha hecho la predicción (y las etiquetas en caso de ser un problema de clasificación).\n",
    "* Inspection: todos los hiperparámetros de un estimator son accesibles directamente mediante variables públicas (imputer.strategy) y los parámetros que haya aprendido son accesibles de la misma manera pero con símbolo de subrayad0 (imputer.strategy_)\n",
    "* Composición de los elementos anteriores. Es fácil realizar acción que incluyen varias acciones por composición de acciones sencillas.\n",
    "* Valores por defecto para la mayoría de hiperparámetros. Esto es bueno porque se puede usar cualquier cosa rápido y malo, porque muchas veces no se sabe lo que se está haciendo.\n",
    " \n",
    "En general, como se verá a continuación, la creación y uso de un modelo inteligente usando `scikit-learn`tiene unos pasos muy claros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd203b",
   "metadata": {},
   "source": [
    "Primero de todo vamos a cargar un conjunto de librerías que, si bien no son propiamente de *machine learning*, nos facilitarán la visualización y la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceabc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a4353",
   "metadata": {},
   "source": [
    "Una vez hecho esto y sabiendo que el entorno que estamos ejecutando tiene las librerías necesarias procedamos a ver un ejemplo paso a paso:\n",
    "\n",
    "### 1. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78379628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# cargamos los datos\n",
    "iris = load_iris()\n",
    "in_data, target = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d32d1b",
   "metadata": {},
   "source": [
    "Dentro de la librería que estamos usando hay ya problemas preparados en este caso vamos a emplear un problema conocido en el mundo del *machine learning* como ejemplo de prueba. Se trata de un problema de clasificación de flores Iris en base a 4 variables:\n",
    "\n",
    "1. Ancho de sépalo\n",
    "2. Largo del sépalo\n",
    "3. Ancho del pétalo\n",
    "4. Larogo del pétalo\n",
    "\n",
    "Con estas entradas se trata de identificar a cual de las 3 posibles variadades que existen pertenece un determinado patrón. Es por tanto un ejemplo de clasificación multiclase pero que en este caso tiene que pertenecer a alguno de esos tres tipos. \n",
    "En el código anterior, la segunda de las líneas lo que hace es cargar cada uno de los datos por separado. Una de las cosas que se evidencia es que es un entrenamiento supervisado ya que tenemos la salida deseada. Este tipo de aproximaciones suele ser el preferido debido a la pontencia de las técnicas actuales en este campo. Ua cosa que se puede hacer con estas bases de datos preparadas por ejemplo es imprimir su descripción que nos dará más datos al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f056230",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1721da",
   "metadata": {},
   "source": [
    "Previamente a continuar, un paso típico en este punto es hacer una primera exploración del código con unas cuantas sentencias de comprobación a fin de realizar lo que se conoce como programación defensiva. Por ejemplo, comprobando los tamaños de las matrices de datos que vamos a utilizar en este punto. Algo muy simple es impormir las dimensiones de esos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensiones del problema {in_data.shape}->{target.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50023bf9",
   "metadata": {},
   "source": [
    "La información que nos muestra este `print` es que tenemos una base de datos con 150 y 4 columnas en la entrada para 150 salidas que tienen un único valor. Esto lo que nos viene a decir es que, como se muestra en la descripción del problema cada una de las filas se corresponde con un ejemplo, instancia o patrón. Estos tienen en cada una de las columnas una de las 4 variables que se van a usar como entrada y que se han identiificado en la descripción. Finalmente en la salida se puede ver que sólo tenemos un valor y es porque en el caso de las 3 clases simplemente son identificadas como 0, 1 y 2. Este se puede comprobar con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Posibles salidas: {np.unique(target)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c99e78",
   "metadata": {},
   "source": [
    "Otra cosa si se quiere ser un poco más refinado es usar aserciones como en el ejemplo siguiente que comprueba que los datos coinciden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51df11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert in_data.shape[0] == target.shape[0], \"No hay el mismo número de ejemplos que de salidas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb7cb1",
   "metadata": {},
   "source": [
    "### 2. Preprocesado\n",
    "Una vez hecho esto se puede proceder al uso de estos datos. Habitualmente esto implicaría una serie de pasos que están contenidos dentro de lo que se conoce como preprocesado o preparación de los datos. En este punto es donde encontraríamos elementos como la limpieza, la completitud, normalización, reducción de la dimensionalidad, etc. En este caso, como los datos ya vienen preparados nos vamos a limitar a hacer un paso que se explicará en detalle porque es necesario en una unidad posterior que es la división de los datos entre entrenamiento y test. Para ello haremos uso de una función de utilidad que está disponible en `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996af66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dividimos los datos en entrenamiento y prueba\n",
    "in_train, in_test, target_train, target_test = train_test_split(in_data, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af68fe87",
   "metadata": {},
   "source": [
    "Esta función lo que hace es coger los datos y dividir el conjunto en dos subconjuntos disjuntos en donde el primero de ellos (entrenamiento, train) tienen el 70% de los datos, y el segundo de ellos (test) contiene el 30% de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a6fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensiones del conjunto de entrenamiento {in_train.shape}->{target_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de test {in_test.shape}->{target_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba7c92",
   "metadata": {},
   "source": [
    "### 3. Creación del modelo\n",
    "El siguiente paso dentro de cualquier sistema es la creación del modelo. En este caso vamos a crear un modelo muy sencillo, una regresión lineal que nos va a permitir clasificar los diferentes ejemplo. En este caso no entraremos a los parámetros del mismo, ya que lo abordaremos en una unidad posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef474f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# entrenamos el modelo\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a904c8",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento\n",
    "Una vez creado el modelo, es necesario ajustarlo. Este proceso conocido como \"entrenamiento\" se hace con el conjunto de entrenamiento llamando a la función `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe2a51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(in_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a251d4",
   "metadata": {},
   "source": [
    "Una vez el modelo se ha ajustado, ya es posible usarlo para realizar clasificaciones o predicciones. De esta manera podemos proceder a usar o \"testear\" el modelo. Puede no parecer demasiado pero el modelo está actualmente en memoria y ajustado con los patrones que se le han pasado de entrada. Iprimamos lo que nos da:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El modelos creado es {clf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a84cf",
   "metadata": {},
   "source": [
    "Este punto implicará que ya se puede hacer uso del modelo, para ello se tiene la llamada al método `predict` como se ve en el código siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = clf.predict(in_test)\n",
    "print(f\"Salida Predicha: {predicted[0:4]}\") # Imprimir una muestra de las salidas predichas\n",
    "print(f\"Salida Real: {target_test[0:4]}\") # Compararlas con las reales para esos patrones\n",
    "\n",
    "assert len(predicted_target) == len(target_test), \"Los indices no se corresponden y no se han calculado las mismas salidas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae314f4",
   "metadata": {},
   "source": [
    "### 5. Evaluación\n",
    "Lo normal es que con una técnica sencialla como esta no todas las salidas sean perfectas y se correspondan. Es por ello que vamos a necesitar alguna manera de mesurar el rendimiento de nuestros modelos. También se abordará más adelante pero, en este punto, nos limitaremos a usar una medida típica de rendimiento como es la presicion (Accuracy) para lon cual la librería en cuestión también nos ofrece una serie de utilidades como vemos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(target_test, predicted_target)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "lineal_predicted = predicted_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479828e0",
   "metadata": {},
   "source": [
    "En este caso concreto, la medida lo que viene a evaluar es cuantas veces ha acertado el modelo sobre el total de los datos de test. En este punto es **MUY IMPORTANTE** recalcar que no se puede realizar la evaluación sobre los datos de entrenamiento o ajuste. En caso de hacerlo, las mediciones serían poco fiables ya que se evaluaría contra un conjunto usado para el ajuste y, por lo tanto, podríamos caer en un fenómeno conocido como sobre ajuste o más comunmente *overfitting* en el que el modelo pierde su capacidad de aprender y pasa a memorizar los ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68b8ff",
   "metadata": {},
   "source": [
    "### 6. Comparación\n",
    "Una vez conseguido ese dato, podríamos crear otro modelo diferente sobre los mismos datos y comparar las medidas de rendimiento. Hagamos justamente esto, pero ya condensado sin las explicaciones y comparemos dos modelos diferentes de clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4626b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# entrenamos el modelo\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(in_train, target_train)\n",
    "\n",
    "# hacemos predicciones en los datos de prueba\n",
    "predicted_target = clf.predict(in_test)\n",
    "\n",
    "# evaluamos el rendimiento del modelo con la precisión\n",
    "acc = accuracy_score(target_test, predicted_target)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa012c8",
   "metadata": {},
   "source": [
    "Como se puede ver en este segundo caso, el resultado es muy superior al primero y por lo tanto podríamos decir que este modelo es mejor para esta partición de datos. Esto veremos que no siempre es así cuando veamos la evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee64924",
   "metadata": {},
   "source": [
    "### 7.Postprocesado\n",
    "Como último paso en cualquier flujo habitual de datos estaría el que hacer con los datos por ejemplo el código siguiente imprime los patrones con el tipo asociado en cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "f = plt.figure()    \n",
    "f, axes = plt.subplots(nrows = 1, ncols = 2, sharex=True, sharey = True)\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "lw = 6\n",
    "\n",
    "for color, i, target_name in zip(colors, [0,1,2], iris.target_names):\n",
    "    examples = predicted_target == i\n",
    "    axes[0].scatter(in_test[examples, 0], in_test[examples, 2], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "axes[0].legend(loc='best', shadow=False, scatterpoints=1)\n",
    "\n",
    "for color, i, target_name in zip(colors, [0,1,2], iris.target_names):\n",
    "    examples = lineal_predicted == i\n",
    "    axes[1].scatter(in_test[examples, 0], in_test[examples, 2], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "axes[1].legend(loc='best', shadow=False, scatterpoints=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f4df5",
   "metadata": {},
   "source": [
    "# Ejercicios propuestos\n",
    "Vale, ya hemos tomado contacto con `scikit-learn` pero la verdad que este ofrece muchísimo más de lo que vemos ahora mismo. Para ser más exactos, tiene todas las utidades y funciones en el siguiente [enlace](https://scikit-learn.org/stable/modules/classes.html). Llegado a este punto lo que se propone es que replique una definición de modelo y entrenamiento con los pasos que hemos visto hasta ahora. Para ello, siga los siguientes pasos:\n",
    "\n",
    "1. Escoja otro problema de clasificación dentro de los que ofrece `scikit-learn`. Puede consultar las diponibles en este [enlace](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets)\n",
    "2. Seleccione otro modelo de clasificación de entre los disponibles que puede consultar [aquí](https://scikit-learn.org/stable/modules/classes.html). Cualquiera de los modelos es utilizable siempre que sea de classificación. Por ejemplo, se recomienda el uso del `KNNClassifier` o el `GaussianNB`.\n",
    "3. Calcula el accuracy del nuevo modelo y compare los resultados con los que ya hemos obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f8ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
